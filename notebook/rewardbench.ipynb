{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061c120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from rewardbench.rewardbench import rewardbench, HfArgumentParser, Args\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "torch.use_deterministic_algorithms(True, warn_only=False)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "model_name_safe = model_name.replace(\"/\", \"_\")\n",
    "output_directory = f\"results/{model_name_safe}\"\n",
    "\n",
    "parser = HfArgumentParser(Args)\n",
    "args, = parser.parse_args_into_dataclasses(args=[\n",
    "    f\"--model={model_name}\",\n",
    "#     f\"--output_dir={output_directory}\", # 指定输出目录以保存结果json\n",
    "    \"--batch_size=32\",\n",
    "    f\"--tokenizer={model_name}\",\n",
    "    \"--chat_template=raw\",\n",
    "    \"--not_quantized\",\n",
    "    \"--attn_implementation=eager\",\n",
    "#     \"--torch_dtype=float32\",\n",
    "])\n",
    "rewardbench(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac5419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817ab83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42625fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Chat': 0.4273743016759777, 'Chat Hard': 0.5109649122807017, 'Safety': 0.4905405405405405, 'Reasoning': 0.7144070224259289}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Chat': 0.5418994413407822, 'Chat Hard': 0.5328947368421053, 'Safety': 0.5783783783783784, 'Reasoning': 0.2940402138920718}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998fdec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chat': 0.32122905027932963,\n",
       " 'Chat Hard': 0.5964912280701754,\n",
       " 'Safety': 0.4905405405405405,\n",
       " 'Reasoning': 0.3875838926174497}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Chat': 0.32122905027932963, 'Chat Hard': 0.5964912280701754, 'Safety': 0.4905405405405405, 'Reasoning': 0.3875838926174497}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67959d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
